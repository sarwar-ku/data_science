{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNZ5aDCubrjWZvhCl0qPR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarwar-ku/data_science/blob/main/Image_classification_YOLO5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLKIEFoD12qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d14081-7b2a-4640-f713-718da8653071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 6.5: Recognizing Multiple Images with YOLO5\n",
        "Programmers typically design convolutional neural networks to classify a single item centered in an image. However, as humans, we can recognize many items in our field of view in real-time. It is advantageous to recognize multiple items in a single image. One of the most advanced means of doing this is YOLOv5. You Only Look Once (YOLO) was introduced by Joseph Redmon, who supported YOLO up through V3. [Cite:redmon2016you] The fact that YOLO must only look once speaks to the efficiency of the algorithm. In this context, to \"look\" means to perform one scan over the image. It is also possible to run YOLO on live video streams.\n",
        "\n",
        "Joseph Redmon left computer vision to pursue other interests. The current version, YOLOv5 is supported by the startup company Ultralytics, who released the open-source library that we use in this class.[Cite:zhu2021tph]\n",
        "\n",
        "Researchers have trained YOLO on a variety of different computer image datasets. The version of YOLO weights used in this course is from the dataset Common Objects in Context (COCO). [Cite: lin2014microsoft] This dataset contains images labeled into 80 different classes. COCO is the source of the file coco.txt used in this module.\n",
        "\n",
        "Using YOLO in Python\n",
        "To use YOLO in Python, we will use the open-source library provided by Ultralytics.\n",
        "\n",
        "YOLOv5 GitHub\n",
        "The code provided in this notebook works equally well when run either locally or from Google CoLab. It is easier to run YOLOv5 from CoLab, which is recommended for this course.\n",
        "\n",
        "We begin by obtaining an image to classify."
      ],
      "metadata": {
        "id": "Wg3_I5Yl7KSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import shutil\n",
        "from IPython.display import Image\n",
        "!mkdir /content/images/\n",
        "\n",
        "URL = \"https://github.com/sarwar-ku/data_science/blob/main/otherfiles/jeff_cook.jpg\"\n",
        "LOCAL_IMG_FILE = \"/otherfiles/otherfiles/jeff_cook.jpg\"\n",
        "\n",
        "with urllib.request.urlopen(URL) as response, \\\n",
        "  open(LOCAL_IMG_FILE, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "Image(filename=LOCAL_IMG_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "uQ5x5hSL7LlP",
        "outputId": "9080b8fe-5427-4032-9fa5-f224760c6037"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/images/’: File exists\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/otherfiles/otherfiles/jeff_cook.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0baca42c1e27>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_IMG_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/otherfiles/otherfiles/jeff_cook.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing YOLOv5\n",
        "YOLO is not available directly through either PIP or CONDA. Additionally, YOLO is not installed in Google CoLab by default. Therefore, whether you wish to use YOLO through CoLab or run it locally, you need to go through several steps to install it. This section describes the process of installing YOLO. The same steps apply to either CoLab or a local install. For CoLab, you must repeat these steps each time the system restarts your virtual environment. You must perform these steps only once for your virtual Python environment for a local install. If you are installing locally, install to the same virtual environment you created for this course. The following commands install YOLO directly from its GitHub repository."
      ],
      "metadata": {
        "id": "Tkm2FBAY7Wdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5 --tag 6.2  # clone\n",
        "!mv /content/6.2 /content/yolov5\n",
        "%pip install -qr /content/yolov5/requirements.txt  # install\n",
        "sys.path.insert(0,'/content/yolov5')\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "id": "8qvCdoQq7Y-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will run YOLO from the command line and classify the previously downloaded kitchen picture. You can run this classification on any image you choose."
      ],
      "metadata": {
        "id": "s4lO2-E97bnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare directories for YOLO command line\n",
        "!rm -R /content/yolov5/runs/detect/*\n",
        "!mkdir /content/images\n",
        "!cp /content/street/jeff_cook.jpg /content/images\n",
        "\n",
        "# Run YOLO to classify\n",
        "!python /content/yolov5/detect.py --weights yolov5s.pt --img 1024 \\\n",
        "  --conf 0.25 --source /content/images/\n",
        "\n",
        "# Display the images\n",
        "from IPython.display import Image\n",
        "\n",
        "URL = '/content/yolov5/runs/detect/exp/jeff_cook.jpg'\n",
        "Image(filename=URL, width=300)"
      ],
      "metadata": {
        "id": "l5QexKFw7dev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running YOLOv5\n",
        "In addition to the command line execution, we just saw. The following code adds the downloaded YOLOv5 to Python's environment, allowing yolov5 to be imported like a regular Python library."
      ],
      "metadata": {
        "id": "vv8HHlEk7pgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
        "\n",
        "# Inference\n",
        "results = yolo_model(LOCAL_IMG_FILE)\n",
        "\n",
        "# Results\n",
        "df = results.pandas().xyxy[0]\n",
        "df"
      ],
      "metadata": {
        "id": "2YeWgimJ7rWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that the yolo class instantiated here is a callable object, which can fill the role of both an object and a function. Acting as a function, yolo returns a Pandas dataframe that contains the bounding boxes (xmin/xmax and ymin/ymax), confidence, and name/class of each item detected.\n",
        "\n",
        "Your program should use these values to perform whatever actions you wish due to the input image. The following code displays the images detected above the threshold.\n",
        "\n",
        "You can obtain the counts of images through the use of a Pandas groupby and pivot."
      ],
      "metadata": {
        "id": "agv_Sk6S7uiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df[['name','class']].groupby(by=[\"name\"]).count().reset_index()\n",
        "df2.columns = ['name','count']\n",
        "df2['image'] = 1\n",
        "df2.pivot(index=['image'],columns='name',values='count').reset_index().fillna(0)"
      ],
      "metadata": {
        "id": "voE3zSVR7y0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}