{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrAWomMSTKr8N6bKW3rD7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarwar-ku/data_science/blob/main/boostrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeThTpRwoWWJ",
        "outputId": "129bde94-750a-491c-9b2e-99e17d67e72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 5.5: Benchmarking Regularization Techniques\n",
        "Quite a few hyperparameters have been introduced so far. Tweaking each of these values can have an effect on the score obtained by your neural networks. Some of the hyperparameters seen so far include:\n",
        "\n",
        "Number of layers in the neural network\n",
        "How many neurons in each layer\n",
        "What activation functions to use on each layer\n",
        "Dropout percent on each layer\n",
        "L1 and L2 values on each layer\n",
        "To try out each of these hyperparameters you will need to run train neural networks with multiple settings for each hyperparameter. However, you may have noticed that neural networks often produce somewhat different results when trained multiple times. This is because the neural networks start with random weights. Because of this it is necessary to fit and evaluate a neural network times to ensure that one set of hyperparameters are actually better than another. Bootstrapping can be an effective means of benchmarking (comparing) two sets of hyperparameters.\n",
        "\n",
        "Bootstrapping is similar to cross-validation. Both go through a number of cycles/folds providing validation and training sets. However, bootstrapping can have an unlimited number of cycles. Bootstrapping chooses a new train and validation split each cycle, with replacement. The fact that each cycle is chosen with replacement means that, unlike cross validation, there will often be repeated rows selected between cycles. If you run the bootstrap for enough cycles, there will be duplicate cycles.\n",
        "\n",
        "In this part we will use bootstrapping for hyperparameter benchmarking. We will train a neural network for a specified number of splits (denoted by the SPLITS constant). For these examples we use 100. We will compare the average score at the end of the 100. By the end of the cycles the mean score will have converged somewhat. This ending score will be a much better basis of comparison than a single cross-validation. Additionally, the average number of epochs will be tracked to give an idea of a possible optimal value. Because the early stopping validation set is also used to evaluate the the neural network as well, it might be slightly inflated. This is because we are both stopping and evaluating on the same sample. However, we are using the scores only as relative measures to determine the superiority of one set of hyperparameters to another, so this slight inflation should not present too much of a problem.\n",
        "\n",
        "Because we are benchmarking, we will display the amount of time taken for each cycle. The following function can be used to nicely format a time span."
      ],
      "metadata": {
        "id": "G8vUTyzsocLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "NYhjbAKtohdp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bootstrapping for Regression\n",
        "Regression bootstrapping uses the ShuffleSplit object to perform the splits. This technique is similar to KFold for cross-validation; no balancing occurs. We will attempt to predict the age column for the jh-simple-dataset; the following code loads this data."
      ],
      "metadata": {
        "id": "sHvOtAsLoilx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for product\n",
        "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
        "df.drop('product', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('age').drop('id')\n",
        "x = df[x_columns].values\n",
        "y = df['age'].values"
      ],
      "metadata": {
        "id": "gHQ0b78DoljK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code performs the bootstrap. The architecture of the neural network can be adjusted to compare many different configurations."
      ],
      "metadata": {
        "id": "sfQA0UYJoo17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CaIE1oF7orVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
        "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(np.array(x_train).astype('float32'),np.array(y_train).astype('float32'),validation_data=(np.array(x_test).astype('float32'),np.array(y_test).astype('float32')),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "\n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(np.array(x_test).astype('float32'))\n",
        "\n",
        "    # Measure this bootstrap's log loss\n",
        "    score = np.sqrt(metrics.mean_squared_error(pred,np.array(y_test).astype('float32')))\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "\n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\"\n",
        "          f\" stdev={mdev:.6f}\",\n",
        "          f\" epochs={epochs}, mean epochs={int(m2)}\",\n",
        "          f\" time={hms_string(time_took)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoJbwFuKoryy",
        "outputId": "9f3a4e3b-f18a-4a78-d988-58bb33511342"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 6ms/step\n",
            "#1: score=0.745393, mean score=0.745393, stdev=0.000000  epochs=112, mean epochs=112  time=0:00:29.81\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#2: score=1.045139, mean score=0.895266, stdev=0.149873  epochs=121, mean epochs=116  time=0:00:22.43\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#3: score=0.623238, mean score=0.804590, stdev=0.177254  epochs=129, mean epochs=120  time=0:00:18.11\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#4: score=0.691162, mean score=0.776233, stdev=0.161172  epochs=117, mean epochs=119  time=0:00:21.44\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#5: score=0.640754, mean score=0.749137, stdev=0.154006  epochs=114, mean epochs=118  time=0:00:21.36\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#6: score=0.753098, mean score=0.749798, stdev=0.140596  epochs=133, mean epochs=121  time=0:00:21.44\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#7: score=0.587712, mean score=0.726642, stdev=0.141987  epochs=143, mean epochs=124  time=0:00:21.60\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#8: score=0.504020, mean score=0.698815, stdev=0.151858  epochs=116, mean epochs=123  time=0:00:21.42\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#9: score=0.717837, mean score=0.700928, stdev=0.143298  epochs=109, mean epochs=121  time=0:00:15.64\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#10: score=1.147544, mean score=0.745590, stdev=0.190874  epochs=116, mean epochs=121  time=0:00:21.35\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#11: score=1.059674, mean score=0.774143, stdev=0.203159  epochs=96, mean epochs=118  time=0:00:21.40\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#12: score=0.644068, mean score=0.763303, stdev=0.197804  epochs=132, mean epochs=119  time=0:00:21.43\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#13: score=0.652537, mean score=0.754783, stdev=0.192323  epochs=133, mean epochs=120  time=0:00:21.65\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#14: score=1.167838, mean score=0.784287, stdev=0.213687  epochs=91, mean epochs=118  time=0:00:16.95\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#15: score=0.504139, mean score=0.765610, stdev=0.217948  epochs=137, mean epochs=119  time=0:00:20.35\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#16: score=0.835954, mean score=0.770007, stdev=0.211713  epochs=129, mean epochs=120  time=0:00:18.23\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#17: score=0.738142, mean score=0.768132, stdev=0.205529  epochs=123, mean epochs=120  time=0:00:17.77\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#18: score=1.082067, mean score=0.785573, stdev=0.212289  epochs=141, mean epochs=121  time=0:00:19.28\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#19: score=0.663394, mean score=0.779143, stdev=0.208420  epochs=128, mean epochs=122  time=0:00:18.91\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#20: score=0.552696, mean score=0.767820, stdev=0.209052  epochs=139, mean epochs=122  time=0:00:21.38\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#21: score=0.706945, mean score=0.764922, stdev=0.204425  epochs=116, mean epochs=122  time=0:00:21.36\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#22: score=0.527430, mean score=0.754126, stdev=0.205760  epochs=107, mean epochs=121  time=0:00:21.60\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#23: score=0.602517, mean score=0.747535, stdev=0.203599  epochs=149, mean epochs=123  time=0:00:22.06\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#24: score=0.732751, mean score=0.746919, stdev=0.199334  epochs=121, mean epochs=123  time=0:00:17.63\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#25: score=0.681937, mean score=0.744319, stdev=0.195721  epochs=112, mean epochs=122  time=0:00:21.41\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#26: score=0.762045, mean score=0.745001, stdev=0.191951  epochs=132, mean epochs=122  time=0:00:19.49\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#27: score=0.562730, mean score=0.738250, stdev=0.191482  epochs=121, mean epochs=122  time=0:00:21.81\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#28: score=0.825710, mean score=0.741374, stdev=0.188731  epochs=118, mean epochs=122  time=0:00:17.70\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#29: score=0.631775, mean score=0.737595, stdev=0.186523  epochs=120, mean epochs=122  time=0:00:16.86\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#30: score=0.567755, mean score=0.731933, stdev=0.185905  epochs=139, mean epochs=123  time=0:00:41.86\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#31: score=0.663967, mean score=0.729741, stdev=0.183276  epochs=110, mean epochs=122  time=0:00:21.71\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#32: score=0.664178, mean score=0.727692, stdev=0.180750  epochs=105, mean epochs=122  time=0:00:21.40\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#33: score=0.716985, mean score=0.727368, stdev=0.178000  epochs=120, mean epochs=122  time=0:00:18.33\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#34: score=1.008404, mean score=0.735633, stdev=0.181677  epochs=117, mean epochs=121  time=0:00:21.64\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#35: score=0.586310, mean score=0.731367, stdev=0.180783  epochs=133, mean epochs=122  time=0:00:20.49\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#36: score=0.482408, mean score=0.724451, stdev=0.182889  epochs=165, mean epochs=123  time=0:00:41.87\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#37: score=1.043367, mean score=0.733071, stdev=0.187667  epochs=93, mean epochs=122  time=0:00:14.68\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#38: score=0.756143, mean score=0.733678, stdev=0.185218  epochs=108, mean epochs=122  time=0:00:17.83\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#39: score=0.544012, mean score=0.728815, stdev=0.185270  epochs=136, mean epochs=122  time=0:00:21.02\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#40: score=0.733629, mean score=0.728935, stdev=0.182941  epochs=120, mean epochs=122  time=0:00:21.70\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#41: score=1.145133, mean score=0.739086, stdev=0.191763  epochs=107, mean epochs=122  time=0:00:15.50\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#42: score=0.568151, mean score=0.735016, stdev=0.191250  epochs=143, mean epochs=122  time=0:00:21.54\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#43: score=0.665324, mean score=0.733396, stdev=0.189305  epochs=134, mean epochs=122  time=0:00:21.40\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#44: score=0.709438, mean score=0.732851, stdev=0.187175  epochs=102, mean epochs=122  time=0:00:21.48\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#45: score=1.161480, mean score=0.742376, stdev=0.195571  epochs=95, mean epochs=121  time=0:00:13.82\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#46: score=0.551408, mean score=0.738225, stdev=0.195428  epochs=131, mean epochs=122  time=0:00:21.38\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#47: score=0.646594, mean score=0.736275, stdev=0.193789  epochs=112, mean epochs=121  time=0:00:16.58\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#48: score=0.653435, mean score=0.734549, stdev=0.192125  epochs=89, mean epochs=121  time=0:00:13.28\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#49: score=1.046354, mean score=0.740913, stdev=0.195198  epochs=106, mean epochs=120  time=0:00:22.24\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#50: score=0.682990, mean score=0.739754, stdev=0.193406  epochs=130, mean epochs=121  time=0:00:21.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bootstrapping process for classification is similar, and I present it in the next section.\n",
        "\n",
        "Bootstrapping for Classification\n",
        "Regression bootstrapping uses the StratifiedShuffleSplit class to perform the splits. This class is similar to StratifiedKFold for cross-validation, as the classes are balanced so that the sampling does not affect proportions. To demonstrate this technique, we will attempt to predict the product column for the jh-simple-dataset; the following code loads this data."
      ],
      "metadata": {
        "id": "c31x0oryp6yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ],
      "metadata": {
        "id": "VWSNaLzsp9ya"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now run this data through a number of splits specified by the SPLITS variable. We track the average error through each of these splits."
      ],
      "metadata": {
        "id": "M16zmTozqDl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1,\n",
        "                                random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x,df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
        "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    #model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "    #          callbacks=[monitor],verbose=0,epochs=1000)\n",
        "\n",
        "    model.fit(np.array(x_train).astype('float32'),np.array(y_train).astype('float32'),validation_data=(np.array(x_test).astype('float32'),np.array(y_test).astype('float32')),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "\n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(np.array(x_test).astype('float32'))\n",
        "\n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(np.array(y_test).astype('float32'),axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "\n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\" +\\\n",
        "          f\"stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)},\" +\\\n",
        "          f\" time={hms_string(time_took)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgTiQi7RqGWq",
        "outputId": "a7caa55e-cc1f-46da-d66f-6de09a4aa2e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "#1: score=0.674864, mean score=0.674864,stdev=0.000000, epochs=64, mean epochs=64, time=0:00:10.93\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#2: score=0.673737, mean score=0.674300,stdev=0.000564, epochs=56, mean epochs=60, time=0:00:11.19\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#3: score=0.659667, mean score=0.669423,stdev=0.006913, epochs=62, mean epochs=60, time=0:00:11.19\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#4: score=0.678015, mean score=0.671571,stdev=0.007049, epochs=61, mean epochs=60, time=0:00:10.09\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#5: score=0.632205, mean score=0.663698,stdev=0.016962, epochs=93, mean epochs=67, time=0:00:13.72\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#6: score=0.686846, mean score=0.667556,stdev=0.017725, epochs=58, mean epochs=65, time=0:00:08.96\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#7: score=0.726102, mean score=0.675919,stdev=0.026249, epochs=56, mean epochs=64, time=0:00:08.41\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#8: score=0.732291, mean score=0.682966,stdev=0.030829, epochs=81, mean epochs=66, time=0:00:11.88\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#9: score=0.629718, mean score=0.677049,stdev=0.033539, epochs=53, mean epochs=64, time=0:00:08.78\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#10: score=0.630348, mean score=0.672379,stdev=0.034766, epochs=78, mean epochs=66, time=0:00:21.35\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#11: score=0.711782, mean score=0.675961,stdev=0.035030, epochs=59, mean epochs=65, time=0:00:08.56\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#12: score=0.742511, mean score=0.681507,stdev=0.038251, epochs=40, mean epochs=63, time=0:00:11.11\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#13: score=0.696302, mean score=0.682645,stdev=0.036962, epochs=80, mean epochs=64, time=0:00:11.98\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#14: score=0.736720, mean score=0.686508,stdev=0.038243, epochs=46, mean epochs=63, time=0:00:07.64\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#15: score=0.659774, mean score=0.684725,stdev=0.037543, epochs=62, mean epochs=63, time=0:00:09.14\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#16: score=0.762395, mean score=0.689580,stdev=0.040925, epochs=42, mean epochs=61, time=0:00:11.54\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#17: score=0.668913, mean score=0.688364,stdev=0.040000, epochs=49, mean epochs=61, time=0:00:11.46\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#18: score=0.662170, mean score=0.686909,stdev=0.039333, epochs=91, mean epochs=62, time=0:00:21.55\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#19: score=0.617509, mean score=0.683256,stdev=0.041302, epochs=55, mean epochs=62, time=0:00:11.16\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#20: score=0.690790, mean score=0.683633,stdev=0.040289, epochs=78, mean epochs=63, time=0:00:22.29\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#21: score=0.662268, mean score=0.682616,stdev=0.039581, epochs=46, mean epochs=62, time=0:00:07.97\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#22: score=0.748276, mean score=0.685600,stdev=0.041018, epochs=52, mean epochs=61, time=0:00:11.41\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#23: score=0.593224, mean score=0.681584,stdev=0.044320, epochs=82, mean epochs=62, time=0:00:21.74\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#24: score=0.733688, mean score=0.683755,stdev=0.044618, epochs=63, mean epochs=62, time=0:00:11.14\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#25: score=0.577319, mean score=0.679497,stdev=0.048437, epochs=103, mean epochs=64, time=0:00:15.27\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#26: score=0.676208, mean score=0.679371,stdev=0.047501, epochs=66, mean epochs=64, time=0:00:11.01\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#27: score=0.731092, mean score=0.681286,stdev=0.047625, epochs=69, mean epochs=64, time=0:00:11.20\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#28: score=0.731700, mean score=0.683087,stdev=0.047694, epochs=40, mean epochs=63, time=0:00:11.23\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#29: score=0.675663, mean score=0.682831,stdev=0.046884, epochs=57, mean epochs=63, time=0:00:11.14\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#30: score=0.737922, mean score=0.684667,stdev=0.047145, epochs=51, mean epochs=63, time=0:00:11.21\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#31: score=0.723636, mean score=0.685924,stdev=0.046886, epochs=61, mean epochs=63, time=0:00:09.38\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#32: score=0.635894, mean score=0.684361,stdev=0.046962, epochs=77, mean epochs=63, time=0:00:11.36\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#33: score=0.627689, mean score=0.682644,stdev=0.047254, epochs=59, mean epochs=63, time=0:00:08.90\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#34: score=0.580530, mean score=0.679640,stdev=0.049648, epochs=77, mean epochs=63, time=0:00:11.64\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#35: score=0.501292, mean score=0.674545,stdev=0.057248, epochs=75, mean epochs=64, time=0:00:21.41\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#36: score=0.634927, mean score=0.673444,stdev=0.056822, epochs=61, mean epochs=63, time=0:00:11.23\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#37: score=0.677314, mean score=0.673549,stdev=0.056052, epochs=60, mean epochs=63, time=0:00:11.26\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#38: score=0.697945, mean score=0.674191,stdev=0.055447, epochs=77, mean epochs=64, time=0:00:11.48\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#39: score=0.745353, mean score=0.676015,stdev=0.055876, epochs=70, mean epochs=64, time=0:00:10.01\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#40: score=0.705064, mean score=0.676742,stdev=0.055359, epochs=58, mean epochs=64, time=0:00:11.43\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#41: score=0.724420, mean score=0.677905,stdev=0.055172, epochs=39, mean epochs=63, time=0:00:06.76\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#42: score=0.683031, mean score=0.678027,stdev=0.054517, epochs=52, mean epochs=63, time=0:00:11.12\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#43: score=0.666235, mean score=0.677752,stdev=0.053908, epochs=65, mean epochs=63, time=0:00:09.93\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#44: score=0.762932, mean score=0.679688,stdev=0.054783, epochs=51, mean epochs=63, time=0:00:11.21\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#45: score=0.650326, mean score=0.679036,stdev=0.054344, epochs=78, mean epochs=63, time=0:00:12.55\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#46: score=0.645483, mean score=0.678306,stdev=0.053972, epochs=69, mean epochs=63, time=0:00:10.63\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#47: score=0.677196, mean score=0.678283,stdev=0.053395, epochs=53, mean epochs=63, time=0:00:08.87\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#48: score=0.752474, mean score=0.679828,stdev=0.053888, epochs=59, mean epochs=63, time=0:00:09.82\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#49: score=0.680259, mean score=0.679837,stdev=0.053336, epochs=75, mean epochs=63, time=0:00:21.45\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#50: score=0.679087, mean score=0.679822,stdev=0.052800, epochs=53, mean epochs=63, time=0:00:08.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarking\n",
        "Now that we've seen how to bootstrap with both classification and regression, we can start to try to optimize the hyperparameters for the jh-simple-dataset data. For this example, we will encode for classification of the product column. Evaluation will be in log loss."
      ],
      "metadata": {
        "id": "aCY0TEZuqPXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],\n",
        "               axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ],
      "metadata": {
        "id": "gy_ucUAbqUhi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed some optimization, and the code has the best settings that I could determine. Later in this book, we will see how we can use an automatic process to optimize the hyperparameters."
      ],
      "metadata": {
        "id": "COQ_yuxVqYOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow.keras.initializers\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
        "\n",
        "SPLITS = 100\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x,df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=x.shape[1], activation=PReLU(), \\\n",
        "        kernel_regularizer=regularizers.l2(1e-4))) # Hidden 1\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4))) # Hidden 2\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4)\n",
        "    )) # Hidden 3\n",
        "#    model.add(Dropout(0.5)) - Usually better performance\n",
        "# without dropout on final layer\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
        "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(np.array(x_train).astype('float32'),np.array(y_train).astype('float32'),validation_data=(np.array(x_test).astype('float32'),np.array(y_test).astype('float32')), \\\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "\n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(np.array(x_test).astype('float32'))\n",
        "\n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(np.array(y_test).astype('float32'),axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "\n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\"\n",
        "          f\"stdev={mdev:.6f}, epochs={epochs},\"\n",
        "          f\"mean epochs={int(m2)}, time={hms_string(time_took)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOdYB0IdqcEE",
        "outputId": "1fc43d33-9de7-464f-a612-d7310870f22c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "#1: score=0.726197, mean score=0.726197,stdev=0.000000, epochs=127,mean epochs=127, time=0:00:43.29\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#2: score=0.637087, mean score=0.681642,stdev=0.044555, epochs=214,mean epochs=170, time=0:00:43.01\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#3: score=0.675545, mean score=0.679610,stdev=0.036493, epochs=242,mean epochs=194, time=0:00:50.18\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "#4: score=0.573676, mean score=0.653126,stdev=0.055704, epochs=247,mean epochs=207, time=0:00:53.80\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#5: score=0.602901, mean score=0.643081,stdev=0.053721, epochs=183,mean epochs=202, time=0:00:38.31\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#6: score=0.610514, mean score=0.637653,stdev=0.050520, epochs=151,mean epochs=194, time=0:00:31.60\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#7: score=0.598932, mean score=0.632122,stdev=0.048695, epochs=225,mean epochs=198, time=0:01:23.58\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#8: score=0.682896, mean score=0.638468,stdev=0.048547, epochs=185,mean epochs=196, time=0:00:40.15\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#9: score=0.692111, mean score=0.644429,stdev=0.048776, epochs=138,mean epochs=190, time=0:00:42.82\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#10: score=0.619408, mean score=0.641927,stdev=0.046878, epochs=170,mean epochs=188, time=0:00:42.71\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "#11: score=0.674469, mean score=0.644885,stdev=0.045665, epochs=186,mean epochs=188, time=0:00:37.12\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#12: score=0.709579, mean score=0.650276,stdev=0.047236, epochs=143,mean epochs=184, time=0:00:44.07\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#13: score=0.682752, mean score=0.652774,stdev=0.046201, epochs=157,mean epochs=182, time=0:00:43.29\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#14: score=0.724222, mean score=0.657878,stdev=0.048173, epochs=136,mean epochs=178, time=0:00:42.79\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#15: score=0.673761, mean score=0.658937,stdev=0.046708, epochs=170,mean epochs=178, time=0:00:39.51\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#16: score=0.666296, mean score=0.659397,stdev=0.045260, epochs=191,mean epochs=179, time=0:01:23.66\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#17: score=0.605627, mean score=0.656234,stdev=0.045695, epochs=197,mean epochs=180, time=0:00:42.70\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#18: score=0.684892, mean score=0.657826,stdev=0.044890, epochs=194,mean epochs=180, time=0:00:36.11\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#19: score=0.782846, mean score=0.664406,stdev=0.051850, epochs=155,mean epochs=179, time=0:00:29.81\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#20: score=0.605608, mean score=0.661466,stdev=0.052136, epochs=161,mean epochs=178, time=0:00:30.27\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#21: score=0.704668, mean score=0.663523,stdev=0.051705, epochs=161,mean epochs=177, time=0:00:42.66\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#22: score=0.662531, mean score=0.663478,stdev=0.050516, epochs=176,mean epochs=177, time=0:00:42.64\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#23: score=0.700778, mean score=0.665100,stdev=0.049988, epochs=145,mean epochs=176, time=0:00:42.69\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#24: score=0.704963, mean score=0.666761,stdev=0.049580, epochs=209,mean epochs=177, time=0:00:39.60\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#25: score=0.726092, mean score=0.669134,stdev=0.049950, epochs=169,mean epochs=177, time=0:00:42.66\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#26: score=0.693393, mean score=0.670067,stdev=0.049202, epochs=135,mean epochs=175, time=0:00:26.00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#27: score=0.671273, mean score=0.670112,stdev=0.048282, epochs=174,mean epochs=175, time=0:00:42.60\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#28: score=0.727767, mean score=0.672171,stdev=0.048605, epochs=174,mean epochs=175, time=0:00:42.62\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#29: score=0.571189, mean score=0.668689,stdev=0.051190, epochs=202,mean epochs=176, time=0:00:38.17\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#30: score=0.674456, mean score=0.668881,stdev=0.050341, epochs=168,mean epochs=176, time=0:00:40.56\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#31: score=0.615202, mean score=0.667149,stdev=0.050422, epochs=186,mean epochs=176, time=0:00:41.78\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#32: score=0.658458, mean score=0.666878,stdev=0.049651, epochs=178,mean epochs=176, time=0:00:38.69\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#33: score=0.685844, mean score=0.667452,stdev=0.049001, epochs=159,mean epochs=176, time=0:00:42.62\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#34: score=0.610114, mean score=0.665766,stdev=0.049237, epochs=152,mean epochs=175, time=0:00:42.67\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#35: score=0.707106, mean score=0.666947,stdev=0.049015, epochs=136,mean epochs=174, time=0:00:42.63\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#36: score=0.642077, mean score=0.666256,stdev=0.048502, epochs=224,mean epochs=175, time=0:00:46.38\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#37: score=0.752804, mean score=0.668595,stdev=0.049858, epochs=147,mean epochs=174, time=0:00:42.62\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#38: score=0.596144, mean score=0.666689,stdev=0.050546, epochs=355,mean epochs=179, time=0:01:09.58\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#39: score=0.672284, mean score=0.666832,stdev=0.049902, epochs=156,mean epochs=178, time=0:00:32.45\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#40: score=0.629974, mean score=0.665911,stdev=0.049609, epochs=141,mean epochs=177, time=0:00:42.65\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#41: score=0.597193, mean score=0.664235,stdev=0.050134, epochs=220,mean epochs=179, time=0:00:42.69\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#42: score=0.693580, mean score=0.664933,stdev=0.049735, epochs=160,mean epochs=178, time=0:00:31.95\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#43: score=0.601638, mean score=0.663461,stdev=0.050071, epochs=220,mean epochs=179, time=0:00:43.60\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#44: score=0.696527, mean score=0.664213,stdev=0.049743, epochs=149,mean epochs=178, time=0:00:30.77\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#45: score=0.659179, mean score=0.664101,stdev=0.049193, epochs=181,mean epochs=178, time=0:00:35.94\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#46: score=0.615063, mean score=0.663035,stdev=0.049178, epochs=192,mean epochs=179, time=0:00:38.84\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#47: score=0.657274, mean score=0.662912,stdev=0.048659, epochs=190,mean epochs=179, time=0:00:38.19\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#48: score=0.633999, mean score=0.662310,stdev=0.048326, epochs=177,mean epochs=179, time=0:00:37.56\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#49: score=0.642353, mean score=0.661903,stdev=0.047914, epochs=226,mean epochs=180, time=0:01:23.71\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#50: score=0.722556, mean score=0.663116,stdev=0.048186, epochs=193,mean epochs=180, time=0:00:49.31\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#51: score=0.643899, mean score=0.662739,stdev=0.047786, epochs=205,mean epochs=181, time=0:00:48.85\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#52: score=0.636269, mean score=0.662230,stdev=0.047464, epochs=315,mean epochs=183, time=0:01:13.04\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#53: score=0.653162, mean score=0.662059,stdev=0.047030, epochs=155,mean epochs=183, time=0:00:37.41\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#54: score=0.675850, mean score=0.662314,stdev=0.046629, epochs=177,mean epochs=182, time=0:00:42.73\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#55: score=0.693724, mean score=0.662885,stdev=0.046394, epochs=165,mean epochs=182, time=0:00:38.00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#56: score=0.669904, mean score=0.663011,stdev=0.045987, epochs=154,mean epochs=182, time=0:00:33.67\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#57: score=0.756943, mean score=0.664659,stdev=0.047221, epochs=149,mean epochs=181, time=0:00:42.74\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#58: score=0.621058, mean score=0.663907,stdev=0.047155, epochs=170,mean epochs=181, time=0:00:36.81\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#59: score=0.668451, mean score=0.663984,stdev=0.046757, epochs=189,mean epochs=181, time=0:00:42.84\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#60: score=0.664864, mean score=0.663999,stdev=0.046366, epochs=150,mean epochs=180, time=0:00:33.02\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#61: score=0.570173, mean score=0.662461,stdev=0.047503, epochs=217,mean epochs=181, time=0:01:23.67\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#62: score=0.678197, mean score=0.662714,stdev=0.047160, epochs=170,mean epochs=181, time=0:00:35.83\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#63: score=0.645678, mean score=0.662444,stdev=0.046832, epochs=245,mean epochs=182, time=0:00:51.04\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#64: score=0.618374, mean score=0.661755,stdev=0.046785, epochs=228,mean epochs=183, time=0:00:47.68\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#65: score=0.686585, mean score=0.662137,stdev=0.046524, epochs=153,mean epochs=182, time=0:00:42.65\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#66: score=0.582708, mean score=0.660934,stdev=0.047179, epochs=176,mean epochs=182, time=0:00:43.35\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#67: score=0.644220, mean score=0.660684,stdev=0.046870, epochs=196,mean epochs=182, time=0:00:39.93\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#68: score=0.654582, mean score=0.660595,stdev=0.046529, epochs=154,mean epochs=182, time=0:00:42.65\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#69: score=0.550111, mean score=0.658993,stdev=0.048041, epochs=309,mean epochs=184, time=0:01:02.58\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#70: score=0.735151, mean score=0.660081,stdev=0.048545, epochs=135,mean epochs=183, time=0:00:42.71\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#71: score=0.684876, mean score=0.660431,stdev=0.048291, epochs=283,mean epochs=184, time=0:00:57.03\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#72: score=0.640519, mean score=0.660154,stdev=0.048011, epochs=283,mean epochs=186, time=0:00:56.18\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#73: score=0.641039, mean score=0.659892,stdev=0.047733, epochs=267,mean epochs=187, time=0:00:54.91\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#74: score=0.621904, mean score=0.659379,stdev=0.047611, epochs=212,mean epochs=187, time=0:00:57.19\n",
            "7/7 [==============================] - 0s 7ms/step\n",
            "#75: score=0.706083, mean score=0.660002,stdev=0.047595, epochs=166,mean epochs=187, time=0:00:51.38\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#76: score=0.669039, mean score=0.660120,stdev=0.047292, epochs=195,mean epochs=187, time=0:01:25.15\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#77: score=0.670349, mean score=0.660253,stdev=0.046999, epochs=214,mean epochs=187, time=0:01:23.83\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#78: score=0.684936, mean score=0.660570,stdev=0.046779, epochs=197,mean epochs=187, time=0:00:46.66\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#79: score=0.659338, mean score=0.660554,stdev=0.046482, epochs=213,mean epochs=188, time=0:01:23.69\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#80: score=0.677635, mean score=0.660768,stdev=0.046230, epochs=170,mean epochs=187, time=0:00:38.99\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#81: score=0.617729, mean score=0.660236,stdev=0.046189, epochs=277,mean epochs=189, time=0:01:23.90\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "#82: score=0.673771, mean score=0.660401,stdev=0.045930, epochs=145,mean epochs=188, time=0:00:43.01\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#83: score=0.707337, mean score=0.660967,stdev=0.045939, epochs=135,mean epochs=187, time=0:00:34.53\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#84: score=0.661494, mean score=0.660973,stdev=0.045665, epochs=167,mean epochs=187, time=0:00:43.39\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#85: score=0.581859, mean score=0.660042,stdev=0.046190, epochs=219,mean epochs=188, time=0:01:23.72\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#86: score=0.683052, mean score=0.660310,stdev=0.045987, epochs=186,mean epochs=188, time=0:01:23.93\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#87: score=0.650372, mean score=0.660196,stdev=0.045734, epochs=233,mean epochs=188, time=0:01:23.75\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#88: score=0.684523, mean score=0.660472,stdev=0.045546, epochs=152,mean epochs=188, time=0:00:31.08\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "#89: score=0.591749, mean score=0.659700,stdev=0.045865, epochs=236,mean epochs=188, time=0:01:24.35\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#90: score=0.652735, mean score=0.659623,stdev=0.045616, epochs=163,mean epochs=188, time=0:00:43.09\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#91: score=0.637418, mean score=0.659379,stdev=0.045423, epochs=171,mean epochs=188, time=0:00:35.44\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#92: score=0.607571, mean score=0.658816,stdev=0.045494, epochs=231,mean epochs=188, time=0:00:47.17\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#93: score=0.623437, mean score=0.658435,stdev=0.045396, epochs=158,mean epochs=188, time=0:00:31.90\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#94: score=0.646390, mean score=0.658307,stdev=0.045170, epochs=166,mean epochs=188, time=0:00:33.59\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#95: score=0.682212, mean score=0.658559,stdev=0.044998, epochs=249,mean epochs=188, time=0:00:52.17\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#96: score=0.752527, mean score=0.659537,stdev=0.045769, epochs=166,mean epochs=188, time=0:00:43.16\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#97: score=0.648759, mean score=0.659426,stdev=0.045545, epochs=298,mean epochs=189, time=0:00:58.12\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#98: score=0.618393, mean score=0.659008,stdev=0.045499, epochs=245,mean epochs=190, time=0:00:46.51\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "#99: score=0.649268, mean score=0.658909,stdev=0.045280, epochs=202,mean epochs=190, time=0:00:43.20\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "#100: score=0.733571, mean score=0.659656,stdev=0.045661, epochs=176,mean epochs=190, time=0:00:42.69\n"
          ]
        }
      ]
    }
  ]
}