{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5fb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=AALBGpLbj6Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2690880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting resource\n",
      "  Downloading Resource-0.2.1-py2.py3-none-any.whl.metadata (478 bytes)\n",
      "Collecting JsonForm>=0.0.2 (from resource)\n",
      "  Downloading JsonForm-0.0.2.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting JsonSir>=0.0.2 (from resource)\n",
      "  Downloading JsonSir-0.0.2.tar.gz (2.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-easyconfig>=0.1.0 (from resource)\n",
      "  Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl.metadata (462 bytes)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\sarwar\\anaconda3\\lib\\site-packages (from JsonForm>=0.0.2->resource) (4.16.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sarwar\\anaconda3\\lib\\site-packages (from python-easyconfig>=0.1.0->resource) (6.0)\n",
      "Requirement already satisfied: six in c:\\users\\sarwar\\anaconda3\\lib\\site-packages (from python-easyconfig>=0.1.0->resource) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\sarwar\\anaconda3\\lib\\site-packages (from jsonschema->JsonForm>=0.0.2->resource) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\sarwar\\anaconda3\\lib\\site-packages (from jsonschema->JsonForm>=0.0.2->resource) (0.18.0)\n",
      "Downloading Resource-0.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl (5.4 kB)\n",
      "Building wheels for collected packages: JsonForm, JsonSir\n",
      "  Building wheel for JsonForm (setup.py): started\n",
      "  Building wheel for JsonForm (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonForm: filename=JsonForm-0.0.2-py3-none-any.whl size=3313 sha256=ef555a204eee608a014f87a73fb63bb48bc49fc35b25b85427406ffdfa858aa0\n",
      "  Stored in directory: c:\\users\\sarwar\\appdata\\local\\pip\\cache\\wheels\\2e\\bd\\ab\\c1026535edf314ce2b0d7ba3b2dd0ca67bfb5bae2cb301510f\n",
      "  Building wheel for JsonSir (setup.py): started\n",
      "  Building wheel for JsonSir (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonSir: filename=JsonSir-0.0.2-py3-none-any.whl size=4752 sha256=87dc2cda6c266c5ffab5af390c2375692b40b559e557e045ea87ef86907fbcae\n",
      "  Stored in directory: c:\\users\\sarwar\\appdata\\local\\pip\\cache\\wheels\\bb\\e7\\72\\08831f4f1927bfcb155f0a971e253bfe677172cebea1332b51\n",
      "Successfully built JsonForm JsonSir\n",
      "Installing collected packages: JsonSir, python-easyconfig, JsonForm, resource\n",
      "Successfully installed JsonForm-0.0.2 JsonSir-0.0.2 python-easyconfig-0.1.7 resource-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\sarwar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sarwar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\sarwar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sarwar\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install resource "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5202b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in tensorflow\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a006990",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\Sarwar\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9336\\1049889229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Brining in tensorflow datasets for fashion mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Bringing in matplotlib for viz stuff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0m_TIMESTAMP_IMPORT_STARTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tfds_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcall_metadata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_call_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\Sarwar\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Brining in tensorflow datasets for fashion mnist \n",
    "import tensorflow_datasets as tfds\n",
    "# Bringing in matplotlib for viz stuff\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f562d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tensorflow datasets api to bring in the data source\n",
    "ds = tfds.load('fashion_mnist', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.as_numpy_iterator().next()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Viz Data and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd589a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some data transformation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection aka iterator\n",
    "dataiterator = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c884bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data out of the pipeline\n",
    "dataiterator.next()['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the subplot formatting \n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# Loop four times and get images \n",
    "for idx in range(4): \n",
    "    # Grab an image and label\n",
    "    sample = dataiterator.next()\n",
    "    # Plot the image using a specific subplot \n",
    "    ax[idx].imshow(np.squeeze(sample['image']))\n",
    "    # Appending the image label as the plot title \n",
    "    ax[idx].title.set_text(sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28323a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and return images only \n",
    "def scale_images(data): \n",
    "    image = data['image']\n",
    "    return image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataset \n",
    "ds = tfds.load('fashion_mnist', split='train')\n",
    "# Running the dataset through the scale_images preprocessing step\n",
    "ds = ds.map(scale_images) \n",
    "# Cache the dataset for that batch \n",
    "ds = ds.cache()\n",
    "# Shuffle it up \n",
    "ds = ds.shuffle(60000)\n",
    "# Batch into 128 images per sample\n",
    "ds = ds.batch(128)\n",
    "# Reduces the likelihood of bottlenecking \n",
    "ds = ds.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27647125",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92760c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Build Neural Network\n",
    "#3.1 Import Modelling Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the sequential api for the generator and discriminator\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Bring in the layers for the neural network\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 Build Generator\n",
    "def build_generator(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Takes in random values and reshapes it to 7x7x128\n",
    "    # Beginnings of a generated image\n",
    "    model.add(Dense(7*7*128, input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "    \n",
    "    # Upsampling block 1 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Upsampling block 2 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c72bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439682a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = generator.predict(np.random.randn(4,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0bdced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new fashion\n",
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "# Setup the subplot formatting \n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# Loop four times and get images \n",
    "for idx, img in enumerate(img): \n",
    "    # Plot the image using a specific subplot \n",
    "    ax[idx].imshow(np.squeeze(img))\n",
    "    # Appending the image label as the plot title \n",
    "    ax[idx].title.set_text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570397c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3 Build Discriminator\n",
    "def build_discriminator(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv Block\n",
    "    model.add(Conv2D(32, 5, input_shape = (28,28,1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Second Conv Block\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Third Conv Block\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Fourth Conv Block\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten then pass to dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30858f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea78485",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51df16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82869190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Construct Training Loop\n",
    "#4.1 Setup Losses and Optimizers\n",
    "# Adam is going to be the optimizer for both\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Binary cross entropy is going to be the loss for both \n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae58cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(learning_rate=0.0001) \n",
    "d_opt = Adam(learning_rate=0.00001) \n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Build Subclassed Model\n",
    "# Importing the base model class to subclass our training step \n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # Pass through args and kwargs to base class \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for gen and disc\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # Get the data \n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as d_tape: \n",
    "            # Pass the real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            # Create labels for real and fakes images\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            # Add some noise to the TRUE outputs\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            # Calculate loss - BINARYCROSS \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Apply backpropagation - nn learn \n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train the generator \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
    "                                        \n",
    "            # Create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            # Calculate loss - trick to training to fake out the discriminator\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of subclassed model\n",
    "fashgan = FashionGAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167dd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 Build Callback\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3297bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 Train\n",
    "# Recommend 2000 epochs\n",
    "hist = fashgan.fit(ds, epochs=20, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Review Performance\n",
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='d_loss')\n",
    "plt.plot(hist.history['g_loss'], label='g_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5eabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Test Out the Generator\n",
    "#5.1 Generate Images\n",
    "generator.load_weights(os.path.join('archive', 'generatormodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ac2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16, 128, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c433dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\n",
    "for r in range(4): \n",
    "    for c in range(4): \n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9075b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2 Save the Model\n",
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
