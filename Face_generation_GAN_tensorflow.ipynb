{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0081b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a76b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory img_align_celeba. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24020\\1600568875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get all images from dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=directory, color_mode='rgb',\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                    shuffle=True, seed=42)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m         )\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    295\u001b[0m                 \u001b[1;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                 \u001b[1;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in directory img_align_celeba. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "directory = 'img_align_celeba'\n",
    "\n",
    "# Get all images from dir\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=directory, color_mode='rgb',\n",
    "                                                   batch_size=128, image_size=(32,32), label_mode=None,\n",
    "                                                   shuffle=True, seed=42)\n",
    "\n",
    "# Normalize the data\n",
    "\n",
    "dataset=dataset.map(lambda x: x /255.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97257f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(dataset)\n",
    "one_batch = next(it).numpy()\n",
    "images = one_batch[:16,:,:,:]\n",
    "\n",
    "# show the image\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(4,4), \n",
    "         axes_pad=0)\n",
    "for ax,im in zip(grid, images):\n",
    "    ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd021ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,BatchNormalization, Dropout, Flatten, Dense, Activation, Reshape\n",
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "def discriminator_model():\n",
    "    disc_input = Input(shape=(32,32,3), name='discriminator_network')\n",
    "    x=Conv2D(filters=64, kernel_size=3, strides=(2,2), padding='same')(disc_input)\n",
    "    x=LeakyReLU()(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(filters=128, kernel_size=3, strides=(2,2), padding='same')(x)\n",
    "    x=LeakyReLU()(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(filters=128, kernel_size=3, strides=(2,2), padding='same')(x)\n",
    "    x=LeakyReLU()(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(filters=64, kernel_size=3, strides=(2,2), padding='same')(x)\n",
    "    x=LeakyReLU()(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    \n",
    "    x=Flatten()(x)\n",
    "    x=Dense(1)(x)\n",
    "    \n",
    "    output = Activation('sigmoid')(x)\n",
    "    \n",
    "    disc=Model(inputs = disc_input, outputs=output)\n",
    "    \n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model = discriminator_model()\n",
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,BatchNormalization, Dropout, Flatten, Dense, Activation, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras import Model, Input\n",
    "def generator_model(z_dim=100):\n",
    "    gen_input = Input(shape=(z_dim), name='generator_network')\n",
    "    \n",
    "    x = Dense(8*8*3)(gen_input)\n",
    "    x = Reshape(target_shape=(8,8,3))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters=512, kernel_size=3, strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters=256, kernel_size=3, strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters=128, kernel_size=3, strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters=128, kernel_size=3, strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "        \n",
    "    x = Conv2DTranspose(filters=64, kernel_size=3, strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters=3, kernel_size=3, strides=(1,1), padding='same')(x)\n",
    "    fake_images_gen = LeakyReLU()(x)\n",
    "    \n",
    "    model_gen=Model(inputs = gen_input, outputs=fake_images_gen)\n",
    "    \n",
    "    return model_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model.summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model = discriminator_model()\n",
    "gen_model = generator_model()\n",
    "# Image Classification CNN\n",
    "# Compile the model that trains disc.\n",
    "disc_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model that trains generator\n",
    "z_dim = 100\n",
    "disc_model.trainable = False\n",
    "model_input = Input(shape=(z_dim), name='model_input')\n",
    "model_output = disc_model(gen_model(model_input))\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(batch, batch_size):\n",
    "    valid = np.ones((batch_size, 1)) \n",
    "    fake = np.zeros((batch_size, 1)) \n",
    "    \n",
    "    disc_model.train_on_batch(batch, valid)\n",
    "    \n",
    "    noise = np.random.normal(0,1, (batch_size, z_dim))\n",
    "    gen_image = gen_model.predict(noise)\n",
    "    disc_model.train_on_batch(gen_image, fake)\n",
    "def train_generator(batch_size):\n",
    "    valid = np.ones((batch_size, 1)) \n",
    "    noise = np.random.normal(0,1, (batch_size, z_dim))\n",
    "    model.train_on_batch(noise, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(fake_image, path):\n",
    "    image = tf.keras.preprocessing.image.array_to_img(fake_image.numpy())\n",
    "    tf.keras.preprocessing.image.save_img(path, image)\n",
    "    return image\n",
    "def generate_and_save_image(path):\n",
    "    noise = np.random.normal(0,1, (1, z_dim))\n",
    "    fake_images = gen_model(noise)\n",
    "    image = save_image(fake_images[0], path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb09f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(10):\n",
    "    print(f'No of Epochs-> {epochs}')\n",
    "    for i,batch in enumerate(dataset):\n",
    "        train_discriminator(batch, batch.shape[0])\n",
    "        train_generator(batch.shape[0])\n",
    "        if i%100==0:\n",
    "            print(f'Batch Images-> {i}')\n",
    "            PATH = 'generate_face'\n",
    "            generate_and_save_image(path = f'{PATH}/epochs_{epochs}batch_{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d6d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
